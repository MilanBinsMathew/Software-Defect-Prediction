{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Software-Defect-Prediction",
      "provenance": [],
      "authorship_tag": "ABX9TyNWnd7w0p8OVywXD3Flsg3D"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEMlVb_5biF0"
      },
      "source": [
        "Importing all nescessary packages."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWiqWojS2qJW"
      },
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "from google.colab import files\n",
        "import io\n",
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.python.framework import ops\n",
        "\n",
        "%matplotlib inline\n",
        "np.random.seed(1)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JdCeRHRAcFkb"
      },
      "source": [
        "Downloading & Printing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pSiCustcEzK"
      },
      "source": [
        "url = 'https://raw.githubusercontent.com/MilanBinsMathew/Software-Defect-Prediction-JM1/main/jm1_csv.csv'"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cFKX_vJCd1Bk",
        "outputId": "2d81b0e9-c180-49c4-9f40-65c15c411181"
      },
      "source": [
        "df = pd.read_csv(url)\n",
        "print(df)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "         loc  v(g)  ev(g)  iv(g)  ...  total_Op  total_Opnd  branchCount  defects\n",
            "0        1.1   1.4    1.4    1.4  ...       1.2         1.2          1.4        0\n",
            "1        1.0   1.0    1.0    1.0  ...       1.0         1.0          1.0        1\n",
            "2       72.0   7.0    1.0    6.0  ...     112.0        86.0         13.0        1\n",
            "3      190.0   3.0    1.0    3.0  ...     329.0       271.0          5.0        1\n",
            "4       37.0   4.0    1.0    4.0  ...      76.0        50.0          7.0        1\n",
            "...      ...   ...    ...    ...  ...       ...         ...          ...      ...\n",
            "10880   18.0   4.0    1.0    4.0  ...      30.0        22.0          7.0        0\n",
            "10881    9.0   2.0    1.0    2.0  ...      19.0        11.0          3.0        0\n",
            "10882   42.0   4.0    1.0    2.0  ...      59.0        44.0          7.0        0\n",
            "10883   10.0   1.0    1.0    1.0  ...      21.0        15.0          1.0        0\n",
            "10884   19.0   3.0    1.0    1.0  ...      31.0        27.0          5.0        0\n",
            "\n",
            "[10885 rows x 22 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2m3WgW3l7zp"
      },
      "source": [
        "Shuffle the dataset and segmenting it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSG4zkugmM0Y"
      },
      "source": [
        "df = df.sample(frac = 1)\n",
        "rng = np.random.RandomState()\n",
        "train = df.sample(frac=0.8, random_state=rng)\n",
        "test = df.loc[~df.index.isin(train.index)]\n",
        "\n",
        "train_X = train.copy()\n",
        "train_Y = train_X.pop('defects')\n",
        "\n",
        "test_X = test.copy()\n",
        "test_Y = test_X.pop('defects')\n",
        "train_Y = pd.Series.to_frame(train_Y)\n",
        "train_Y = train_Y.T\n",
        "test_Y = pd.Series.to_frame(test_Y)\n",
        "test_Y = test_Y.T\n",
        "\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IkBX-aeSlj-3"
      },
      "source": [
        "Cost Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOTxKiTzll7-"
      },
      "source": [
        "\n",
        "def cost(logits, labels):\n",
        "\n",
        "    z = tf.compat.v1.placeholder(tf.float32, name=\"z\")\n",
        "    y = tf.compat.v1.placeholder(tf.float32, name=\"y\")\n",
        "    \n",
        "    cost = tf.nn.sigmoid_cross_entropy_with_logits(logits=z, labels=y)\n",
        "    \n",
        "   \n",
        "    sess = tf.compat.v1.Session()\n",
        "\n",
        "    cost = sess.run(cost, feed_dict={z: logits, y: labels})\n",
        "   \n",
        "    sess.close()\n",
        "    \n",
        "    return cost"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3VMk2pJri8R"
      },
      "source": [
        "Creating Place Holders for X and Y"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4G-KTc-ArmWC"
      },
      "source": [
        "def create_placeholders(n_x, n_y):\n",
        "  X = tf.compat.v1.placeholder(tf.float32, [n_x, None], name = \"X\")\n",
        "  Y = tf.compat.v1.placeholder(tf.float32, [n_y, None], name = \"Y\")\n",
        "  return X,Y"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2rWS3crnMva"
      },
      "source": [
        "Initialize Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wbso4gW0r_zM"
      },
      "source": [
        "def initialize_parameters():\n",
        "  tf.random.set_seed(1)\n",
        "  initializer = tf.keras.initializers.GlorotUniform()\n",
        "\n",
        "  W1= tf.Variable(tf.initializers.GlorotUniform()(shape=(16,8708)))\n",
        "  b1 = tf.Variable(tf.zeros_initializer()(shape=(16,1)))\n",
        "  W2= tf.Variable(tf.initializers.GlorotUniform()(shape=(8,16)))\n",
        "  b2 = tf.Variable(tf.zeros_initializer()(shape=(8,1)))\n",
        "  W3= tf.Variable(tf.initializers.GlorotUniform()(shape=(4,8)))\n",
        "  b3 = tf.Variable(tf.zeros_initializer()(shape=(4,1)))\n",
        "  W4= tf.Variable(tf.initializers.GlorotUniform()(shape=(1,4)))\n",
        "  b4 = tf.Variable(tf.zeros_initializer()(shape=(1,1)))\n",
        "\n",
        "  parameters = {\"W1\": W1,\n",
        "                \"b1\": b1,\n",
        "                \"W2\": W2,\n",
        "                \"b2\": b2,\n",
        "                \"W3\": W3,\n",
        "                \"b3\": b3,\n",
        "                \"W4\": W4,\n",
        "                \"b4\": b4}\n",
        "  return parameters"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ktVa94aPxXjS"
      },
      "source": [
        "Forward Propagation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TZgUlkbxblE"
      },
      "source": [
        "def forward_propagation(X, parameters):\n",
        "  W1 = parameters['W1']\n",
        "  b1 = parameters['b1']\n",
        "  W2 = parameters['W2']\n",
        "  b2 = parameters['b2']\n",
        "  W3 = parameters['W3']\n",
        "  b3 = parameters['b3']\n",
        "  W4 = parameters['W4']\n",
        "  b4 = parameters['b4']\n",
        "  \n",
        "  Z1 = tf.add(tf.matmul(W1,X), b1)\n",
        "  A1 = tf.nn.relu(Z1)\n",
        "  Z2 = tf.add(tf.matmul(W2,A1), b2)\n",
        "  A2 = tf.nn.relu(Z2)\n",
        "  Z3 = tf.add(tf.matmul(W3,A2), b3)\n",
        "  A3 = tf.nn.relu(Z3)\n",
        "  Z4 = tf.add(tf.matmul(W4,A3), b4)\n",
        "  \n",
        "  return Z4  "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sr0B5V99yqj_"
      },
      "source": [
        "Compute End Cost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CC0IPIh6ysWC"
      },
      "source": [
        "def compute_cost(Z4, Y):\n",
        "  logits = tf.transpose(Z4)\n",
        "  labels = tf.transpose(Y)\n",
        "\n",
        "  cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = logits, labels = labels))\n",
        "\n",
        "  return cost"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbThRd2CzghW"
      },
      "source": [
        "Final Implementation Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G63SrhkLzmKx"
      },
      "source": [
        "def model(X_train, Y_train, X_test, Y_test, learning_rate = 0.0001, num_epochs = 1500, print_cost = True):\n",
        "  ops.reset_default_graph()\n",
        "  tf.random.set_seed(1)\n",
        "  seed = 3\n",
        "\n",
        "  (n_x,m) = X_train.shape\n",
        "  n_y = Y_train.shape[0]\n",
        "  costs=[]\n",
        "  X,Y = create_placeholders(n_x, n_y)\n",
        "\n",
        "  parameters = initialize_parameters()\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    Z4 = forward_propagation(X, parameters)\n",
        "    cost = compute_cost(Z4,Y)\n",
        "\n",
        "  optimizer = tf.optimizers.SGD (learning_rate=0.0001)\n",
        "  optimizer = tf.keras.optimizers.Adam().minimize(cost, var_list = parameters, tape = tape)\n",
        "\n",
        "  init = tf.compat.v1.global_variables_initializer()\n",
        "\n",
        "  with tf.compat.v1.Session() as sess:\n",
        "    sess.run(init)\n",
        "    for epoch in range(num_epochs):\n",
        "      epoch_cost = 0\n",
        "      seed = seed+1\n",
        "      _ , batch_cost = sess.run([optimizer, cost], feed_dict={X: X_train, Y: Y_train})\n",
        "\n",
        "      epoch_cost += batch_cost\n",
        "\n",
        "      if print_cost == True and epoch % 100 == 0:\n",
        "        print (\"Cost after epoch %i: %f\" % (epoch, epoch_cost))\n",
        "      if print_cost == True and epoch % 5 == 0:\n",
        "        costs.append(epoch_cost)\n",
        "    plt.plot(np.squeeze(costs))\n",
        "    plt.ylabel('cost')\n",
        "    plt.xlabel('iterations (per tens)')\n",
        "    plt.title(\"Learning rate =\" + str(learning_rate))\n",
        "    plt.show()\n",
        "    \n",
        "    parameters = sess.run(parameters)\n",
        "    print(\"Parameters have been trained\")\n",
        "\n",
        "    correct_prediction = tf.equal(tf.argmax(Z4), tf.argmax(Y))\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
        "\n",
        "    print(\"Train Accuracy:\", accuracy.eval({X: X_train, Y: Y_train}))\n",
        "    print(\"Test Accuracy:\", accuracy.eval({X: X_test, Y: Y_test}))\n",
        "\n",
        "    return parameters"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhJLhXG-139i"
      },
      "source": [
        "Running the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "oqjhpjiC17li",
        "outputId": "60c36286-9a19-4c2d-fbd9-b22c3452b1d5"
      },
      "source": [
        "\n",
        "parameters = model(train_X, train_Y, test_X, test_Y)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1374\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1375\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1376\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1359\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1360\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1452\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1453\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Incompatible shapes: [21,1] vs. [8708,1]\n\t [[{{node gradient_tape/logistic_loss/mul/BroadcastGradientArgs}}]]",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-2ed3181d0af0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_Y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_Y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-14-94de8f3eb32a>\u001b[0m in \u001b[0;36mmodel\u001b[0;34m(X_train, Y_train, X_test, Y_test, learning_rate, num_epochs, minibatch_size, print_cost)\u001b[0m\n\u001b[1;32m     25\u001b[0m       \u001b[0mepoch_cost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m       \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m       \u001b[0m_\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mbatch_cost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m       \u001b[0mepoch_cost\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch_cost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    966\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 968\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    969\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1189\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1191\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1192\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1367\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1368\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1369\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1370\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1371\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1392\u001b[0m                     \u001b[0;34m'\\nsession_config.graph_options.rewrite_options.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1393\u001b[0m                     'disable_meta_optimizer = True')\n\u001b[0;32m-> 1394\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=no-value-for-parameter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1396\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Incompatible shapes: [21,1] vs. [8708,1]\n\t [[node gradient_tape/logistic_loss/mul/BroadcastGradientArgs (defined at <ipython-input-14-94de8f3eb32a>:18) ]]\n\nOriginal stack trace for 'gradient_tape/logistic_loss/mul/BroadcastGradientArgs':\n  File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.7/dist-packages/traitlets/config/application.py\", line 845, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelapp.py\", line 499, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.7/asyncio/events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n    handler_func(fileobj, events)\n  File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 448, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 477, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 431, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-15-2ed3181d0af0>\", line 2, in <module>\n    parameters = model(train_X, train_Y, test_X, test_Y)\n  File \"<ipython-input-14-94de8f3eb32a>\", line 18, in model\n    optimizer = tf.keras.optimizers.Adam().minimize(cost, var_list = parameters, tape = tape)\n  File \"/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py\", line 521, in minimize\n    loss, var_list=var_list, grad_loss=grad_loss, tape=tape)\n  File \"/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py\", line 572, in _compute_gradients\n    grads_and_vars = self._get_gradients(tape, loss, var_list, grad_loss)\n  File \"/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py\", line 454, in _get_gradients\n    grads = tape.gradient(loss, var_list, grad_loss)\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/backprop.py\", line 1090, in gradient\n    unconnected_gradients=unconnected_gradients)\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/imperative_grad.py\", line 77, in imperative_grad\n    compat.as_str(unconnected_gradients.value))\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/backprop.py\", line 159, in _gradient_function\n    return grad_fn(mock_op, *out_grads)\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_grad.py\", line 1377, in _MulGrad\n    SmartBroadcastGradientArgs(x, y, grad))\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_grad.py\", line 110, in SmartBroadcastGradientArgs\n    rx, ry = gen_array_ops.broadcast_gradient_args(sx, sy)\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_array_ops.py\", line 750, in broadcast_gradient_args\n    \"BroadcastGradientArgs\", s0=s0, s1=s1, name=name)\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 750, in _apply_op_helper\n    attrs=attr_protos, op_def=op_def)\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\", line 3569, in _create_op_internal\n    op_def=op_def)\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\", line 2045, in __init__\n    self._traceback = tf_stack.extract_stack_for_node(self._c_op)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmgJDktLQj6K"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}